This code is originally from https://github.com/saki4510t/UVCCamera/
It was modified by infiray, and later by netman.
And by now everything was rewritten by netman except libuvc_build/libuvc.mk xD

The versions of third party things in libinficam/src/main/jni dir:
	libusb    - master at 4622bfcf44db373c53502e3fe873bd611e8332f6 (untouched)
	libuvc    - master at 15925fed1a08462965a2d24a585a0b0c41d6a9ef (patched)
		modified stream.c to prevent a segmentation fault when starting streams
			it was merged upstream, now we are at commit e3f36909ec37b1892ac944872fe9f0369f5601bd
		again patched stream.c to fix a disconnect issue
			again taken upstream, current is identical to upstream d3318ae72a2b916ae352ad0abbbfa2c0990f455e

Short description of the C++ classes in jni/InfiCam dir:
	- UVCDevice     just a wrapper around libuvc, reason for it existing is that using libuvc with android gets pretty involved
	- InfiFrame     that's where i dumped everything to do with analyzing a frame as it comes out of the camera
	- InfiCam       connecting to the camera, feeding the frames to InifFrame class, etc
	- InfiCamJNI    whatever garbage is needed to glue InfiCam class to the Java end

TODO
	- 400 celcius range works quite badly because the float math falls apart below a certain temperature
	- don't forget to reference/put license for libuvc_build makefile, libuvc, libusb if adding license in root
	- figure out where i want to go with the UI part
	- setting for regular shutter interval
	- audio recording along with video
	- setting for resolution of pictures, video
	- don't clear stuff like disconnected message if not connected
	- we can flip the image upside down via the vertex shader, might or might not be useful for the
	    image capturing thing that has to flip the image (maybe more trouble than it's worth just
	    for that) but it may turn out useful in the future
	- audio along with the video
	- rarely but does happen the video gets stuck while camera is still connected (shutter commands still works)
		why what how?
	- the libinficam part should work on linux/windows with small work
		the main thing would be implementing InfiCam and UVCDevice .connect() variation that takes a more sensible
		device specifier than just a FD, and having a palette to feed to setPalette()

Things i learned about the protocol these thermal cameras talk:
	last 4 lines of the frame have parameters (note that the pointer math is in steps of 16 bytes because unsigned short)
		unsigned short *fourLinePara = orgData + requestWidth * (requestHeight - 4);

	there's an offset depending on the width, again note that the pointer math is in steps of 16 bytes because unsigned short
		int amountPixels=0;
		switch (requestWidth)
		{
			case 384:
				amountPixels=requestWidth*(4-1);
				break;
			case 240:
				amountPixels=requestWidth*(4-3);
				break;
			case 256:
				amountPixels=requestWidth*(4-3);
				break;
			case 640:
				amountPixels=requestWidth*(4-1);
				break;
				// NOTE there's more info about this in libthermometry.so
		}

	uint8_t *param = fourLinePara;

		Location  | Datatype        | Parameter
		------------------------------------------------------
		  0 -   2 | 16bit uint      | FPA Average, whatever that means (also detectAvg somewhere)
		  2 -   4 | 16bit uint      | FPA temperature (convert to celcius is weird and depends on camera)
		  4 -   6 | 16bit uint      | Max point X
		  6 -   8 | 16bit uint      | Max point Y
		  8 -  10 | 16bit uint      | Max temperature
		 10 -  12 | 16bit uint      | Min point X
		 12 -  14 | 16bit uint      | Min point Y
		 14 -  16 | 16bit uint      | Min temperature
		 16 -  18 | 16bit uint      | Average temperature (orgAvg elsewhere)
		 18 -  24 | ???             | ??? (unused by software)
		 24 -  26 | 16bit uint      | Center temperature
		 26 -  28 | 16bit uint      | User point 1 temperature
		 28 -  30 | 16bit uint      | User point 2 temperature
		 30 -  32 | 16bit uint      | User point 3 temperature

	uint8_t *param = fourLinePara + amountPixels

		Location  | Datatype        | Parameter
		------------------------------------------------------
		  0 -   2 | 16bit uint      | ??? (cal_00 / v5 / cx) (presumeably calibration value)
		  2 -   4 | 16bit uint      | Shutter temperature (times 10, in kelvin)
		  4 -   6 | 16bit uint      | Core temperature (times 10, in kelvin)
		  6 -  10 | float (32bit)   | ??? (cal_01 / flt_10003360) (presumeably calibration value)
		 10 -  14 | float (32bit)   | ??? (cal_02 / flt_1000335C) (presumeably calibration value)
		 14 -  18 | float (32bit)   | ??? (cal_03 / flt_1000339C) (presumeably calibration value)
		 18 -  22 | float (32bit)   | ??? (cal_04 / flt_10003398) (presumeably calibration value)
		 22 -  26 | float (32bit)   | ??? (cal_05 / flt_10003394) (presumeably calibration value)
		 26 -  48 | ???             | ??? (unused by software)
		 48 -  64 | 16 byte string  | Firmware version
		 64 -  80 | 16 byte string  | Serial number
		 80 -  95 | 16 byte string  | Product name
		 95 - 254 | ???             | ??? (unused bgy software)
		---User area, writeable by ABS_ZOOM command-----------
		254 - 258 | float (32bit)   | Correction
		258 - 262 | float (32bit)   | Reflected temperature
		262 - 266 | float (32bit)   | Air temperature
		266 - 270 | float (32bit)   | Humidity
		270 - 274 | float (32bit)   | Emissivity
		274 - 278 | 16bit uint      | Distance (NOTE i want to try and see if i can store a float there)
		278 - ??? | ???             | Possibly more user area (presumeably 128 bytes of it, java reads that much)

	The user values are saved by:
		setValue(UVCCamera.CTRL_ZOOM_ABS, 0x80ff);

	CTRL_ZOOM_ABS is used with the following commands:
		- < 0x80 in the high byte as an adress to write the low byte in user area
		- 0x8000 to click the shutter
		- 0x8004 called on start, not sure what it does, "切换数据输出8004原始8005yuv,80ff保存"
			* 8005 sets a different mode, the camera seems to default to 0x8004
				... or the camera remembers the last mode... maybe 0x80FF saves this too?
			* Strong indications the output is YUV encoded video in 8005 mode.
		- 0x8020 to set -20 to 120C range (followed by shutter)
		- 0x8021 to set 120 to 400C range (followed by shutter)
		- 0x80FF (as before) to store user area in non-volatile storage
		- 0xEC.., 0xEE.. Mark dead pixel with x, y to low bytes? "用户盲元表" (MainActivity suggests as much)

Some maybe useful trivia:
	* Generating an ironbow palette:
		uint32_t palette[InfiCam::palette_len];
		for (int i = 0; i + 4 <= sizeof(palette); i += 4) {
			double x = (double) i / (double) sizeof(palette);
			((uint8_t *) palette)[i + 0] = round(255 * sqrt(x));
			((uint8_t *) palette)[i + 1] = round(255 * pow(x, 3));
			((uint8_t *) palette)[i + 2] = round(255 * fmax(0, sin(2 * M_PI * x)));
			((uint8_t *) palette)[i + 3] = 255;
		}
		cam.set_palette(palette);

	* Generating a rainbow palette:
		// TODO add partial (0-270 degrees) rainbow, where cold is blue and red is hot
		for (int i = 0; i + 4 <= sizeof(ic.palette); i += 4) {
			double h = 360.0 - (double) i / (double) sizeof(ic.palette) * 360.0;
			double x = (1 - abs(fmod(h / 60.0, 2) - 1));
			double r, g, b;
			if (h >= 0 && h < 60)
				r = 1, g = x, b = 0;
			else if (h >= 60 && h < 120)
				r = x, g = 1, b = 0;
			else if (h >= 120 && h < 180)
				r = 0, g = 1, b = x;
			else if (h >= 180 && h < 240)
				r = 0, g = x, b = 1;
			else if (h >= 240 && h < 300)
				r = x, g = 0, b = 1;
			else r = 1, g = 0, b = x;
			((uint8_t *) ic.palette)[i + 0] = round(255 * r);
			((uint8_t *) ic.palette)[i + 1] = round(255 * g);
			((uint8_t *) ic.palette)[i + 2] = round(255 * b);
			((uint8_t *) ic.palette)[i + 3] = 255;
		}

	drawing stuff to a bitmap for overlay
		// First is just drawing to a bitmap, we may not need this
		Bitmap bmp = Bitmap.createBitmap(640, 480, Bitmap.Config.ARGB_8888);
		Canvas c = new Canvas(bmp);
		Paint p = new Paint();
		p.setColor(Color.TRANSPARENT);
		c.drawRect(new Rect(0, 0, 640, 480), p);
		c.drawLine(0, 0, 640, 480, p2);

		Paint p2 = new Paint();
		p2.setColor(Color.RED);
		SurfaceMuxer.InputSurface is = new SurfaceMuxer.InputSurface(surfaceMuxer, true);
		SurfaceTexture st = is.getSurfaceTexture();
		st.setDefaultBufferSize(640, 480);
		//st.setOnFrameAvailableListener(et2);
		Surface s = is.getSurface();
		Canvas cvs = s.lockCanvas(null);
		//cvs.drawBitmap(bmp, 0, 0, null);
		cvs.drawLine(0, 0, 640, 480, p2);
		s.unlockCanvasAndPost(cvs);
		surfaceMuxer.inputSurfaces.add(is);

	use of the CameraTest class
		/*askPermission(Manifest.permission.CAMERA, granted -> {
			if (granted) {
				SurfaceTexture ist = surfaceMuxer.createInputSurfaceTexture();
				ist.setDefaultBufferSize(1280, 960);
				CameraTest ct = new CameraTest();
				ct.initCamera2(this, new Surface(ist));
				//ist.setOnFrameAvailableListener(surfaceMuxer); // TODO set the right one
			} else {
				showMessage(R.string.permdenied_cam, true);
			}
		});*/

On the stackoverflow that inspired the cubic interpolation shader (
	https://stackoverflow.com/questions/13501081/efficient-bicubic-filtering-code-in-glsl )
	the idea of applying the same concept with Catmull-Rom interpolation is mentioned, but this
	does not work for reasons I only partially understand, i've played around with it though and
	thus I have implemented the basis functions for that, maybe it's useful some day:
		vec4 cmspline(float x) { // See: DOI:10.3390/mca21030033
			float x2 = x * x;
			float x3 = x2 * x;
			float a = 1.0;
			return vec4(
				(-x + 2.0 * x2 - x3) * a,
				2.0 + (a - 6.0) * x2 + (4.0 - a) * x3,
				x * a + (6.0 - 2.0 * a) * x2 - (4.0 - a) * x3,
				(-x2 + x3) * a
			) * 0.5;
		}

To test the interpolation i slapped this into onCreate()
	// We may need setSize on the InputSurface() if we do this again
	// TODO this is just test for interpolation
	/*SurfaceMuxer.InputSurface test = new SurfaceMuxer.InputSurface(surfaceMuxer, true);
	test.getSurfaceTexture().setDefaultBufferSize(8, 6);
	Canvas tcvs = test.getSurface().lockCanvas(null);
	Paint p = new Paint();
	tcvs.drawColor(Color.YELLOW);
	p.setColor(Color.BLUE);
	tcvs.drawLine(0, 6, 8, 0, p);
	p.setColor(Color.RED);
	tcvs.drawLine(0, 0, 8, 6, p);
	test.getSurface().unlockCanvasAndPost(tcvs);
	surfaceMuxer.inputSurfaces.add(test);
	surfaceMuxer.onFrameAvailable(test.getSurfaceTexture());*/